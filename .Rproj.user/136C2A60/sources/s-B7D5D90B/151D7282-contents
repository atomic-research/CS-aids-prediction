---
title: "R Notebook"
author: "Jorge Vald√©s Kroff and Giuli Dussias"
date: "June 7, 2017"
output:
  html_document:
    df_print: paged
---
##Preliminaries

We will load the necessary R libraries and import the data files. Remember, if the following libraries are not available, i.e., you get an error, then you will need to run `install.packages()` first, with the name of the package appearing in double quotes. 

```{r}
library(tidyverse)
library(lme4)
library(ez)
library(multcomp)
#upload the datasource file
#upload the data files, which are in two batches
str(datasource)
str(Aleks_Batch1)
str(Aleks_Batch2)

library(anchors)

Aleks_Batch2$RECORDING_SESSION_LABEL <- as.character(Aleks_Batch2$RECORDING_SESSION_LABEL)
Aleks_Batch2$RECORDING_SESSION_LABEL[Aleks_Batch2$RECORDING_SESSION_LABEL =="p08"] <- "p09"
count(Aleks_Batch2, RECORDING_SESSION_LABEL)

Aleks_Batch2$RECORDING_SESSION_LABEL <- as.factor(Aleks_Batch2$RECORDING_SESSION_LABEL)

Aleks_Batch2 <- subset(Aleks_Batch2, select = -blocks)
str(Aleks_Batch3)
Aleks_Batch3 <-subset(Aleks_Batch3, select = -c(blocks, RIGHT_INTEREST_AREAS))
str(Aleks_Batch3)

```
Combine the two batches into one single dataset. 

```{r}
all_batches <- as.data.frame(rbind(Aleks_Batch1,Aleks_Batch2, Aleks_Batch3))
str(all_batches)
count(all_batches, RECORDING_SESSION_LABEL)
```


##Recode Fixations, Saccades, Blinks

In this experiment, we have three experimenter manipulated variables.

  *target frequency
    +H
    +L
  *language
    +CS
    +S


There are 2 interest areas, with 1 = target, 2 = distractor, . can be outside looks. so we will recode the interest area to also include outside looks, and then we will reate a column that indicates whether the eye was in fixation, blink, saccade. We can also remove the practice trials.
```{r}
all_batches_exp <- all_batches %>% 
  filter(status == "exp") %>% 
  mutate(Look = ifelse(RIGHT_INTEREST_AREA_ID == "1" & RIGHT_IN_BLINK == "0" & RIGHT_IN_SACCADE == "0", "1", ifelse(RIGHT_INTEREST_AREA_ID == "2" & RIGHT_IN_BLINK == "0" & RIGHT_IN_SACCADE == "0", "2", ifelse(RIGHT_INTEREST_AREA_ID == "." & RIGHT_IN_BLINK == "0" & RIGHT_IN_SACCADE == "0", "3", "4"))))
str(all_batches_exp)
count(all_batches_exp, status)
count(all_batches_exp, RECORDING_SESSION_LABEL)
```

##Response Accuracy

We will also want to calculate behavioral accuracy for the participants (we anticiapte performance to be near ceiling). It is possible that there may be a difference on behavioral performance between the 3 blocks. 
```{r}
select <- dplyr::select
accuracy_file <- all_batches_exp %>% 
  filter(SAMPLE_MESSAGE == "SOUND_WORD") %>% 
  select(RECORDING_SESSION_LABEL, TRIAL_INDEX, list, condition, ACCURACY)
str(accuracy_file)
#keep this file
write.csv(accuracy_file, "data/Accuracy_full.csv", row.names = FALSE)
#continue working and summarize this file
accuracy_summary <- accuracy_file %>% 
  group_by(RECORDING_SESSION_LABEL, list, ACCURACY) %>% 
  summarize(Accuracy = n()) %>% 
  complete(ACCURACY, fill = list(Accuracy = 0))
str(accuracy_summary)
View(accuracy_summary)
write.csv(accuracy_summary, "data/Accuracy_summary.csv", row.names = FALSE)
count(all_batches_exp, RECORDING_SESSION_LABEL)
```
It seems like one of the participants was coded wrong, participant 9, list 1, is missing, and there are two participant 8's. Recoded above.


There is something strange about the number of correct/incorrect responses per block. This seems to be specific to Block3, which has 2 repeated trials, and Bocks 2 and 4, in which certain blocks only have 19 trials counted instead of 20. At this point, we don't know why this might be. 
Here we plot the results.
```{r}
ggplot(accuracy_summary[accuracy_summary$ACCURACY == "correct",], aes(list, Accuracy)) + stat_summary(fun.y = mean, geom = "point")
```
##Time Standardization and Binning

We need to create a new Time variable that standardizes the TIMESTAMP. Our interest period duration was 1000 ms, so the TIMESTAMP should go from 1:1000. Then, we will cut the Time scale into 20 ms bins, which will then allow us to aggregate the looks into their appropriate bins. 


Now we will `cut()` the **Time** column into 20 ms bins.
```{r}
#included Time column
all_batches_exp_1001 <- all_batches_exp[-seq(1, NROW(all_batches_exp), by = 1001),]
all_batches_exp_1001_t <- all_batches_exp_1001 %>%
  mutate(Time = rep(seq(1:1000), times = 480))

bini <- seq(0, 1000, by = 20)
#define breaks

#define labels
breaki <- seq(20,1000, by = 20)

#create new column with correct bins
all_batches_exp_bins <- all_batches_exp_1001_t %>%
  mutate(Bins = cut(Time, bini, labels = breaki))

str(all_batches_exp_bins)

#took out every 1001 row cause we have 32032 trials per participant, not 32000

```
Now we will aggregate the data by Look (which region fixations occur) and bin this by the Bins column. We will want to preserve **RECORDING_SESSION_LABEL, Block, same_diff, error** columns as well. 

we should separate column condition into language and frequency before we proceed
```{r}
all_batches_exp_bins_sep <- all_batches_exp_bins %>%
  separate(condition, into = c("language","freq"), sep = "_", remove = TRUE)
str(all_batches_exp_bin_sep)

aggregated_batches <- all_batches_exp_bins_sep %>% 
  filter(ACCURACY == "correct") %>% 
  group_by(RECORDING_SESSION_LABEL, language, freq, Bins, Look) %>% 
  summarize(Counts = n()) %>% 
  complete(Look, fill = list(Counts = 0)) 
View(aggregated_batches)
```
Now we can create proportions based off of the counts.
```{r}
aggregated_batches2 <- aggregated_batches %>% 
  group_by(RECORDING_SESSION_LABEL, language, freq, Bins) %>% 
  mutate(Total = sum(Counts), Prop = Counts/Total)

```
We've discovered some further information that is relevant for the design. Each block has 20 trials (except for File 3) and is equally composed of 10 *same* trials and 10 *different* trials. The error levels are blocked by **Block**, meaning that **Files 1** and **3** do not contain errors but **File 2** does. 

##Plots

Now, we will plot the data. We will focus on plotting the proportion of fixations to targets over time. This will be facetted by Block.
First, we will remove participants who had significant track loss
```{r}
loss <- aggregated_batches2 %>% 
  filter(Look == "4") %>% 
  group_by(RECORDING_SESSION_LABEL) %>% 
  summarize(Mean_Loss = mean(Prop))
aggregated_batches2$Bins <- as.integer(aggregated_batches2$Bins)
```
There are 3 participants who have high track loss: aletra3, miglop2, natmor2. So we will remove them and then plot the data.
```{r}
aggregated_batches2 %>% 
  filter(Prop <= 0.8 & Look == "1") %>% 
  ggplot(data = ., aes(Bins, Prop, color = freq)) +
  stat_summary(fun.y = mean, geom = "point") + 
  stat_smooth() +
  facet_wrap(~language)
```

```{r}
aggregated3 <- aggregated_batches2 %>% 
  filter(Prop <= .8) %>% 
  group_by(language, freq, Bins, Look) %>% 
  summarize(Mean_Prop = mean(Prop))
```
Plot
```{r}
ggplot(aggregated3[aggregated3$Look == "1",], aggregated3[aggregated3$Look == "2",], aes(as.integer(Bins), Mean_Prop, color = freq)) + 
  geom_point() +
  geom_smooth() +
  facet_wrap(~language)
```
I just need to replace the **Bins** column with the original **Time** column which somehow got changed when I coerced the vector into an integer vector. A very simple way to do this is to just create a new column, e.g., **Time**, where we multiply the value in Bins by 20. 
```{r}
aggregated_batches2 <-  aggregated_batches2 %>% 
  mutate(Time = Bins*20)
##replot the original graph with new Timescale:
aggregated_batches2 %>% 
  filter(Prop <= 0.8 & Look == "1") %>% 
  ggplot(data = ., aes(Time, Prop, color = freq)) +
  stat_summary(fun.y = mean, geom = "point") + 
  stat_smooth() +
  facet_wrap(~language)
```
##Analysis

We will be analyzing the proption of fixations to target items as the dependent variable with the following independent variables: same_diff (whether the distractor is the same or different gender), Block (in which block of 3 were they, where block 2 only contains gender errors for different gender trials). We will need to define our time window(s) of analysis. 
By visually inspecting the graphs, it seems fair to have one principle region of analysis which goes from 0 to 500 ms from word onset, and to have this divided into an earlier (1-250) and later (251-500) time region. We will also go ahead and recode the **Block** column using dummy coding where we will code **Block 2** as the reference level to which **Blocks 1 and 3** are tested against. 
```{r}
##creating a new column in which we recode the time windows into early, late, later time windows
aggregated_with_lateearly <- aggregated_batches2 %>% 
  mutate(Region = ifelse(Time <= 250, "early", ifelse(Time > 250 & Time <= 500, "late", "later")))
head(aggregated_with_lateearly)
tail(aggregated_with_lateearly)
aggregated_with_lateearly$Region <- as.factor(aggregated_with_lateearly$Region)
```
Let's now test out the basic model with just the early region (and remember to remove participants who did not look at any region at least .8 during the entire time window. We are only interested in Target looks, so we will further reduce the dataset to only include looks to target items.
```{r}
early_sub <- aggregated_with_lateearly %>% 
  filter(Region == "early" & Prop <= 0.8 & Look == "1")
early_sub
library(nlme)
early_sub$language <- as.factor(early_sub$language)
early_sub$freq <- as.factor(early_sub$freq)
early_model <- lme(Prop ~ language*freq, random = ~1 +  language*freq|RECORDING_SESSION_LABEL,early_sub)
```
To now see the results, we can use the `summary()` function.
```{r}
summary(early_model)

#the more the instructions are spanish xD the smaller the proportion of looks to the target?

anova(early_model)
```
The model converged. We have a fairly strong interaction, so we can test this interaction for follow-ups. I use the `multcomp` package to accomplish this. To do so, we first need to create a column that uniquely indicates the distinct levels of the interaction, then we run a single regression model on this interaction term and then we use the 
```{r}
library(multcomp)
early_sub <- early_sub %>% 
  mutate(Block_levels = interaction(Block, same_diff))

early_interaction <- lmer(Prop ~ Block_levels + (1 + Block_levels|RECORDING_SESSION_LABEL), data = early_sub, REML = FALSE)

early_pairs <- glht(early_interaction,linfct=mcp(Block_levels = "Tukey"))
summary(early_pairs)
```
Now we can repeat the process for the late time region.
```{r}
late_sub <- aggregated_with_lateearly %>% 
  filter(Region == "late" & Prop <= 0.8 & Look == "1")
late_model <- lme(Prop ~ language*freq, random= ~1 + language*freq|RECORDING_SESSION_LABEL, data = late_sub)
summary(late_model)
```
There is a main effect for **Block** as well as an interaction, so we will follow-up on the interaction.
```{r}
late_sub <- late_sub %>% 
  mutate(Block_levels = interaction(Block, same_diff))

late_interaction <- lmer(Prop ~ Block_levels + (1 + Block_levels|RECORDING_SESSION_LABEL), data = late_sub, REML = FALSE)

late_pairs <- glht(late_interaction,linfct=mcp(Block_levels = "Tukey"))
summary(late_pairs)
```

